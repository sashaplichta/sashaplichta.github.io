---
layout: default
modal-id: 202
date: 2024-01-01
img: labelled_detectron2.png
alt: image-alt
project-date:
where:
category:
description: |
    [Detectron2](https://github.com/facebookresearch/detectron2) is an awesome model developed by Facebook's AI Research capable of a ton of computer vision tasks including object detection, instance segmentation, semantic segmentation, keypoint detection, and more. In my work, I really only used it for instance segmentation (the MaskRCNN version), so that's what I'll focus on for this description. 

    # The Basics
    First, what is RCNN? You might know that CNN stands for convolutional neural network, but the R is specific to Facebook's model. Here, it stands for Region, and refers to the fact that the model works by proposing regions of interest (ROIs) within which to do downstream tasks like segmentation. This lets the model overcome some of the issues associated with other large computer vision models, namely losing context as the input size grows and struggling with fine details. The Detectron2 model broadly consists of a feature extracting backbone, a region proposal network, and a collection of heads that act on the proposed regions.

    ### Backbone
    For the backbone, the model uses a ResNet architecture to extract features from the input at decreasing resolutions. That is to say, the backbone is structured like an encoder in that it contracts as it gets deeper. At each level, the outputs are passed to the ROI heads to give them access to both more granular and high-level encodings of the input.

    ### RPN
    Using the increasingly dense outputs of the model backbone, the region proposal network (RPN) finds bounding boxes for areas of high "objectness" (basically areas that are likely to contain an object). These boxes can be, and often are, overlapping and capture different parts of an actual object of interest to the model. In order to minimize this redundancy and start moving to capturing the whole of object, a non-maximum suppression (NMS) algorithm is used to generate 1000 regions of interests (ROIs). NMS is a technique often used in object-detection applications to combined overlapping bounding boxes. NMS isn't the focus of this post, but in essence it uses each bounding boxes confidence score (in our case how "object-like" it is) along with how overlapping boxes are to maximize both the coverage and confidence of the final bounding boxes by retaining only the highest confidence boxes for a given area. In the case of Detectron2, the output of the RPN is cut down to 1000 ROIs, each with an associated confidence score. 

    ### ROI Heads
    Before being fed to the ROI heads, the proposal boxes are first classified as either foreground or background based on their IOU (intersection over union). In doing so, we can again use NMS to cut down from our 1000 proposed ROIs to 512 (or however many we choose) ROIs to be fed to the actual model heads. Rather than feeding the coordinates of each ROI to the heads, we want to use the features we extracted earlier. At first glance there's a bit of an issue - our ROIs are all different sizes, which would be difficult/impossible for our heads to deal with, given that they are just a couple of linear layers rather than CNNs. To get around this, the authors assign each ROI to a feature level (remember the pyramid structure of our backbone) using the formula below. This lets us use a constant sized crop to represent each box, since in each increasing embedding level, we effectively are representing more of the image for each (x,y) coordinate.

    $$ \lfloor 4 + \log_2 \left( \frac{\sqrt{box\_area}}{224} \right) \rfloor $$

    Once assigned to a feature embedding level, each ROI's features are formed as a 7 x 7 crop of its feature level, centered at the boxes center. This pooling is performed by the ROIAlign algorithm and ensure that our input to the ROI heads is a consistent size. This lets us feed our ROI embeddings to our ROI heads which then perform the actual classification, segmentation, etc. Once we stitch those back together, we've got our result! With these components working together, Detectron2 achieves remarkable accuracy and efficiency in a wide range of computer vision tasks - plus, since it's open source, it can serve as a great base for a variety of fine-tuned applications.

---